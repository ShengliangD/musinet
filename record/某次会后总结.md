# 流程
  确定训练数据(midi文件)
  使用jmusic将midi文件转换为xml文件
  将xml文件转换为训练数据格式F，使用模型M来学习
  使M输出音乐
  转换回midi格式或其他可以听的格式

# 上周的测试
## 格式
pitch,rhythmValue pitch,rhythValue ...Value pitch,rhythValue ...

## 模型
char-rnn

## 效果
可以听到声音，就像小孩乱按出来的

## 改进方向（按照我个人认为的优先级排序）
1. 训练数据的格式还需要简化，刚才让它输出的时候还出现了格式错误……，可以考虑pitch和rhythmValue都用二进制表示
2. 使用其他模型训练
3. 输入数据是我随便选的，正式训练的时候要对音乐进行分类；
4. 如果是用char-rnn的话，正式训练的时候可以把模型的超参数设置大一些，层数多一些(由2改到3)

# 目前的进度
数据已收集
相关工具集已经做好
训练流程已大致确定

# 接下来的工作
1. 更改训练数据格式　×
二进制　（邓）
加强度，合
分
丰富古典音乐数据集　（马凯）
工具链方便化
抽取音轨　（郭，戈）
4. 遗传算法？？！　（郭，戈）
