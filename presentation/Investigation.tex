\section{调研成果}
经过调研，我们知道目前有六个较大型的机器自动作曲项目，下面进行简单的分析。
    \subsection{Magenta}
    Magenta是Google的一个开源的深度学习音乐生成项目。该项目在2016年6月开源，目前实现了一个基于常规RNN的模型和两个LSTM的模型。

    它可以处理任何单声道mid文件，其团队正在积极改进模型并增加功能。对于每个模型，Magenta已经提供了一个训练捆绑包，其中有数千个mid文件，可以直接使用这些预先训练的模型生成新的mid文件。

    但是Magenta只能生成单个音符流，也就是说其生成的音乐只能是单音轨的，他们正努力将生成的旋律通过人为的加上鼓点或吉他，但是到目前为止仍未真正解决这一问题。

    其github网址如下

    \url{https : //github.com/tensorflow/magenta}

    \subsection{DeepJazz}
    Deepjazz是Ji-Sung Kim在一次hackathon（编程马拉松)中用36小时完成的作品。它处理的对象同样是mid文件，其模型是一个两层的LSTM。

    它可以通过在单个mid文件上进行训练来创建一些爵士乐，它先将一个mid文件遍历多次，然后可以进行创作。

    不同于Magenta，它可以处理和弦。但它其实是将爵士乐转换成单乐器和单音轨，最后生成的音乐同样是单乐器、单音轨的。

    其github网址如下

    \url{https : //github.com/jisungk/deepjazz}

    \subsection{BachBot}
    BachBot是剑桥大学Feynman Liang团队的成果。它面向的是巴赫的音乐，主体模型同样是LSTM。

    它创造的巴赫的音乐几乎可以以假乱真，而且它可以处理多达4个声道的声音。

    如果给BachBot一个声道的声音，它可以很完美的补上三个声道，从而形成一首完美的曲子，但是如果不这样做，它的表现就差强人意了。

    \subsection{FlowMachines}
    FlowMachines是索尼旗下的一个团队的作品。他所使用的神经网络技术是Markov constraints。

    目前为止，它通过“分析”近 13000份世界各地不同风格的乐谱(主要是爵士乐和流行音乐也有很多巴西音乐、百老汇和其他音乐风格)，在人类作曲家协助下完成了一首披头士风格的流行音乐制作。

    但是，在音乐生成的过程中音乐家的工作是不可或缺的，也就是说，并不是常人点击一个按钮就可以创造音乐。

    \subsection{WaveNet}
    WaveNet是Google DeepMind的研究人员所创建的项目。WaveNet主要基于卷积神经网络。需要说明的是，该项目的目的并不是机器自动作曲，它的主要目的是通过训练使得机器能更更好的完成文本转语音功能，但其基本原理仍然是输入音频和输出音频。

    不同于以上的几个项目，WaveNet的输入并非音符数据而是原始音频，于是也就不存在有关音轨的问题，它可以产生任何种类的声音。

    由于原始音频数据量之庞大，该算法计算上十分昂贵，需要几分钟的时间来训练一秒钟的声音。

    \subsection{GRUV}
    GRUV是斯坦福的一个研究项目，它同样采用原始波形作为输入。其神经网络技术基于LSTM和GRU。

    GRUV是世界上最早的一个公布的以原始波形作为输入的自动作曲项目，它以Madeon的歌曲作为训练数据，并成功生成了一些歌曲。

    GRUV面临着与WaveNet同样的问题，并且该项目研究人员没有时间和计算能力进行进一步研究，该项目受制于硬件和软件两方面的原因没有更进一步。

    其github网址如下

    \url{https：//github.com/MattVitelli/GRUV}

    \subsection{小结}
    我们可以看到，这几个项目主要分为以音符数据为输入和以原始波形为输入的两类。在以音符数据为输入的一类中，无一例外的遇到了关于多音轨处理的问题；而在原始波形这一类中，大多受制于昂贵的计算成本和硬件需求。这两类中，音符类的计算复杂度要低得多，但是相应的，其生成音乐的复杂性也不能向后者那样达到与整个语料库的组合同等复杂，仅仅只能达到与语料库中的单曲同等复杂。

    还有一个问题是，目前为止的几个结果中，生成音乐时，都需要作曲家的协助，并非简单地点击按钮就可以得到想要的音乐，这与我们最初的期望还相去甚远。
 
